{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building CNN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CNN widely known for their applications in\n",
    "  * Image recognition\n",
    "  * Object detection\n",
    "* Basic CNN architecture can be shown as\n",
    "  * <img src = \"visuals/cnn_basic_architecture.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.559706Z",
     "iopub.status.busy": "2025-06-08T14:20:48.559370Z",
     "iopub.status.idle": "2025-06-08T14:20:48.564982Z",
     "shell.execute_reply": "2025-06-08T14:20:48.563893Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.559685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import correlate2d\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Convolution Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**what do we need for the convolution layers ???**\n",
    "* we need <u>number of filters</u> that we want to slide over the input data to extract different features.\n",
    "  * we need to tell what is the <u>input size</u> to scan on.\n",
    "  * we need <u>filter size</u> of these filters. Filters are square size, so we need only 1 dimension.\n",
    "  * we need to tell <u>output shape</u> (shape obtained after convolution). Formula is, $$\\text{Output shape} = \\frac{\\text{Input shape} - \\text{filter size} + 2*\\text{padding}}{\\text{Stride}}+1$$\n",
    "    > If stride increases, output dimension will decrease. However, if padding increases, output dimension will increase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.566966Z",
     "iopub.status.busy": "2025-06-08T14:20:48.566710Z",
     "iopub.status.idle": "2025-06-08T14:20:48.581294Z",
     "shell.execute_reply": "2025-06-08T14:20:48.580362Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.566945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "''' Initialize basic attributes of a convolution class '''\n",
    "class Convolution:\n",
    "    def __init__(self, input_shape, filter_size, num_filters):\n",
    "        # get height and width from input_shape\n",
    "        input_height, input_width = input_shape\n",
    "        self.input_shape = input_shape    # input to scan on?\n",
    "        self.num_filters = num_filters    # how many filters?\n",
    "        self.filter_shape = (num_filters, filter_size, filter_size) \n",
    "\n",
    "        # with zero padding and a stride of 1\n",
    "        self.output_shape = (num_filters, \n",
    "                             input_height - filter_size + 1, \n",
    "                             input_width - filter_size + 1)\n",
    "        \n",
    "        self.filters = np.random.randn(*self.filter_shape)   # weights\n",
    "        self.biases = np.random.randn(*self.output_shape)    # and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pass in Covolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how convolution happens in forward pass,\n",
    "As an example, consider an input as follows,\n",
    "$$ \\begin{bmatrix} 1 & 2 & 3 & 0\\\\ 0 & 1 & 2 & 3\\\\ 3 & 2 & 1 & 0\\\\ 0 & 1 & 2 & 1\\end{bmatrix} $$\n",
    "and kernel as follows,\n",
    "$$ \\begin{bmatrix} 1 & 0 \\\\ 0 & -1\\end{bmatrix} $$\n",
    "\n",
    "Sliding this kernel on top-left window, i.e.,\n",
    "$$ \\begin{bmatrix} 1 & 2 \\\\ 0 & 1\\end{bmatrix} $$\n",
    "\n",
    "will give, $1*1 + 2*0 + 0*0 + 1*-1 = 0$ as the element in (1, 1) of output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.582492Z",
     "iopub.status.busy": "2025-06-08T14:20:48.582161Z",
     "iopub.status.idle": "2025-06-08T14:20:48.600086Z",
     "shell.execute_reply": "2025-06-08T14:20:48.599237Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.582471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "''' This is forward pass in convolution - effectively the conv process '''\n",
    "def conv_forward(self, input_data):\n",
    "    # assign input data to class attribute\n",
    "    self.input_data = input_data\n",
    "    \n",
    "    # Initialized the input value\n",
    "    output = np.zeros(self.output_shape)\n",
    "\n",
    "    # each convolution will give 1 layer, and thus each will be stacked.\n",
    "    # output[0] will be first layer, output[1] will be second layer and so on ...\n",
    "    for i in range(self.num_filters):\n",
    "        output[i] = correlate2d(self.input_data, self.filters[i], mode=\"valid\")\n",
    "    \n",
    "    # Applying Relu Activation function\n",
    "    ### ReLU is an element-wise operation. It simply replaces all \n",
    "    ### negative values with zero and leaves positive values unchanged, \n",
    "    ### keeping the shape intact.\n",
    "    output = np.maximum(output, 0)\n",
    "    \n",
    "    return output \n",
    "\n",
    "# assign to Convolution class\n",
    "Convolution.forward = conv_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"visuals/cnn_forward.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Pass in Covolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"visuals/cnn_backward.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.602347Z",
     "iopub.status.busy": "2025-06-08T14:20:48.602031Z",
     "iopub.status.idle": "2025-06-08T14:20:48.626524Z",
     "shell.execute_reply": "2025-06-08T14:20:48.625379Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.602323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "''' Method for backward pass in convolution layer '''\n",
    "def conv_backward(self, dL_dz, lr):\n",
    "    # Create a random dL_dout array to accommodate output gradients\n",
    "    dL_dinput = np.zeros_like(self.input_data)\n",
    "    dL_dw = np.zeros_like(self.filters)\n",
    "\n",
    "    # we will do this for all layers of filters\n",
    "    for i in range(self.num_filters):\n",
    "        # Calculating the gradient of loss with respect to filter\n",
    "        ### Question is \"How much does changing this filter affect the output?\"\n",
    "        dL_dw[i] = correlate2d(self.input_data, \n",
    "                               dL_dz[i],\n",
    "                               mode=\"valid\")\n",
    "\n",
    "        # Calculating the gradient of loss with respect to inputs\n",
    "        dL_dinput += correlate2d(dL_dz[i],\n",
    "                                 self.filters[i], \n",
    "                                 mode=\"full\")\n",
    "\n",
    "    # Updating the parameters with learning rate\n",
    "    self.filters -= lr * dL_dw\n",
    "    self.biases -= lr * dL_dz\n",
    "\n",
    "    # returning the gradient of inputs\n",
    "    return dL_dinput\n",
    "\n",
    "Convolution.backward = conv_backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Max-Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.627849Z",
     "iopub.status.busy": "2025-06-08T14:20:48.627569Z",
     "iopub.status.idle": "2025-06-08T14:20:48.642501Z",
     "shell.execute_reply": "2025-06-08T14:20:48.641601Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.627828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "''' This is class for max pooling layer '''\n",
    "class MaxPool:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass in Max-Pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the forward pass of Max Pooling, the input is taken from the output of the convolution operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.643950Z",
     "iopub.status.busy": "2025-06-08T14:20:48.643617Z",
     "iopub.status.idle": "2025-06-08T14:20:48.666143Z",
     "shell.execute_reply": "2025-06-08T14:20:48.665125Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.643924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pool_forward(self, input_data):\n",
    "    self.input_data = input_data\n",
    "\n",
    "    # num_channels is actually the number of filters\n",
    "    # input_height and input_width are dimensions as a result of convolution\n",
    "    self.num_channels, self.input_height, self.input_width = input_data.shape\n",
    "    \n",
    "    # each pooling window covers pool_size Ã— pool_size pixels \n",
    "    # and produces one output, reducing the spatial size by that factor\n",
    "    self.output_height = self.input_height // self.pool_size\n",
    "    self.output_width = self.input_width // self.pool_size\n",
    "\n",
    "    # Determining the output shape\n",
    "    self.output = np.zeros((self.num_channels, \n",
    "                            self.output_height, \n",
    "                            self.output_width))\n",
    "\n",
    "    # Iterating over different channels\n",
    "    for c in range(self.num_channels):\n",
    "        # Looping through the height\n",
    "        for i in range(self.output_height):\n",
    "            # looping through the width\n",
    "            for j in range(self.output_width):\n",
    "\n",
    "                # Starting postition\n",
    "                start_i = i * self.pool_size\n",
    "                start_j = j * self.pool_size\n",
    "\n",
    "                # Ending Position\n",
    "                end_i = start_i + self.pool_size\n",
    "                end_j = start_j + self.pool_size\n",
    "\n",
    "                # Creating a patch from the input data\n",
    "                patch = input_data[c, start_i:end_i, start_j:end_j]\n",
    "\n",
    "                #Finding the maximum value from each patch/window\n",
    "                self.output[c, i, j] = np.max(patch)\n",
    "\n",
    "    return self.output\n",
    "\n",
    "MaxPool.forward = pool_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the above code, we have multiple kernels/filters, resulting in multiple feature maps (multiple channels).\n",
    "* To handle this, we need three nested loops.\n",
    "* The outermost loop iterates over each of these feature maps, while the other two loops traverse the height and width of the feature maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass in Max-Pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **We do not calculate gradients in max pooling layer.**\n",
    "* Instead, we transmit the maximum gradients obtained from the previous layer directly to the corresponding locations in the next layer.\n",
    "* This process ensures that the maximum gradient values flow through the MaxPooling layer and continue propagating through the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.744692Z",
     "iopub.status.busy": "2025-06-08T14:20:48.744239Z",
     "iopub.status.idle": "2025-06-08T14:20:48.751456Z",
     "shell.execute_reply": "2025-06-08T14:20:48.750557Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.744669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "''' This method covers backward pass through the max pooling layer '''\n",
    "def pool_backward(self, dL_dz, lr):\n",
    "    # initialize gradients wrt inputs\n",
    "    dL_dinput = np.zeros_like(self.input_data)\n",
    "\n",
    "    for c in range(self.num_channels):\n",
    "        for i in range(self.output_height):\n",
    "            for j in range(self.output_width):\n",
    "                start_i = i * self.pool_size\n",
    "                end_i = start_i + self.pool_size\n",
    "                \n",
    "                start_j = j * self.pool_size                \n",
    "                end_j = start_j + self.pool_size\n",
    "                \n",
    "                patch = self.input_data[c, start_i:end_i, start_j:end_j]\n",
    "\n",
    "                # this creates a binary mask of 1 where max value occurred,\n",
    "                # 0 elsewhere\n",
    "                mask = patch == np.max(patch)\n",
    "\n",
    "                # dL_dz[c,i,j] is the incoming gradient and it is only\n",
    "                # assigned to max location in the patch\n",
    "                # In other words, The gradient from the next layer is \n",
    "                # broadcasted back only to the position that won in max pooling.\n",
    "                dL_dinput[c,start_i:end_i, start_j:end_j] = dL_dz[c, i, j] * mask\n",
    "\n",
    "    return dL_dinput\n",
    "\n",
    "MaxPool.backward = pool_backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected (Dense) Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.753456Z",
     "iopub.status.busy": "2025-06-08T14:20:48.753145Z",
     "iopub.status.idle": "2025-06-08T14:20:48.771957Z",
     "shell.execute_reply": "2025-06-08T14:20:48.771085Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.753427Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "''' This class if for fully connected layer '''\n",
    "class Fully_Connected:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size # Size of the inputs coming\n",
    "        self.output_size = output_size # Size of the output producing\n",
    "        self.weights = np.random.randn(output_size, self.input_size)\n",
    "        self.biases = np.random.rand(output_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.773004Z",
     "iopub.status.busy": "2025-06-08T14:20:48.772775Z",
     "iopub.status.idle": "2025-06-08T14:20:48.788538Z",
     "shell.execute_reply": "2025-06-08T14:20:48.787540Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.772986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fc_softmax(self, z):\n",
    "    # Shift the input values to avoid numerical instability\n",
    "    shifted_z = z - np.max(z)\n",
    "    exp_values = np.exp(shifted_z)\n",
    "    sum_exp_values = np.sum(exp_values, axis=0)\n",
    "    log_sum_exp = np.log(sum_exp_values)\n",
    "\n",
    "    # Compute the softmax probabilities\n",
    "    probabilities = exp_values / sum_exp_values\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "Fully_Connected.softmax = fc_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.789638Z",
     "iopub.status.busy": "2025-06-08T14:20:48.789386Z",
     "iopub.status.idle": "2025-06-08T14:20:48.805477Z",
     "shell.execute_reply": "2025-06-08T14:20:48.804541Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.789611Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fc_softmax_derivative(self, s):\n",
    "    return np.diagflat(s) - np.dot(s, s.T)\n",
    "\n",
    "Fully_Connected.softmax_derivative = fc_softmax_derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass in dense layer (including flattening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.808140Z",
     "iopub.status.busy": "2025-06-08T14:20:48.807862Z",
     "iopub.status.idle": "2025-06-08T14:20:48.827805Z",
     "shell.execute_reply": "2025-06-08T14:20:48.826896Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.808119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fc_forward(self, input_data):\n",
    "    self.input_data = input_data\n",
    "\n",
    "    # flatten layer\n",
    "    flattened_input = input_data.flatten().reshape(1, -1)\n",
    "\n",
    "    # z = w.a + b\n",
    "    self.z = np.dot(self.weights, flattened_input.T) + self.biases\n",
    "\n",
    "    # Applying Softmax\n",
    "    self.output = self.softmax(self.z)\n",
    "    return self.output\n",
    "\n",
    "Fully_Connected.forward = fc_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass in dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.828944Z",
     "iopub.status.busy": "2025-06-08T14:20:48.828647Z",
     "iopub.status.idle": "2025-06-08T14:20:48.847047Z",
     "shell.execute_reply": "2025-06-08T14:20:48.846065Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.828917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fc_backward(self, dL_dout, lr):\n",
    "    # Calculate the gradient of the loss with respect to the pre-activation (z)\n",
    "    dL_dy = np.dot(self.softmax_derivative(self.output), dL_dout)\n",
    "    \n",
    "    # Calculate the gradient of the loss with respect to the weights (dw)\n",
    "    dL_dw = np.dot(dL_dy, self.input_data.flatten().reshape(1, -1))\n",
    "\n",
    "    # Calculate the gradient of the loss with respect to the biases (db)\n",
    "    dL_db = dL_dy\n",
    "\n",
    "    # Calculate the gradient of the loss with respect to the input data (dL_dinput)\n",
    "    dL_dinput = np.dot(self.weights.T, dL_dy)\n",
    "    dL_dinput = dL_dinput.reshape(self.input_data.shape)\n",
    "\n",
    "    # Update the weights and biases based on the learning rate and gradients\n",
    "    self.weights -= lr * dL_dw\n",
    "    self.biases -= lr * dL_db\n",
    "\n",
    "    # Return the gradient of the loss with respect to the input data\n",
    "    return dL_dinput\n",
    "\n",
    "Fully_Connected.backward = fc_backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.848566Z",
     "iopub.status.busy": "2025-06-08T14:20:48.848153Z",
     "iopub.status.idle": "2025-06-08T14:20:48.866627Z",
     "shell.execute_reply": "2025-06-08T14:20:48.865788Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.848538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(predictions, targets):\n",
    "    num_samples = 10\n",
    "\n",
    "    # Avoid numerical instability by adding a small epsilon value\n",
    "    epsilon = 1e-7\n",
    "    predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "    loss = -np.sum(targets * np.log(predictions)) / num_samples\n",
    "    return loss\n",
    "\n",
    "def cross_entropy_loss_gradient(actual_labels, predicted_probs):\n",
    "    num_samples = actual_labels.shape[0]\n",
    "    gradient = -actual_labels / (predicted_probs + 1e-7) / num_samples\n",
    "\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.867763Z",
     "iopub.status.busy": "2025-06-08T14:20:48.867489Z",
     "iopub.status.idle": "2025-06-08T14:20:48.887642Z",
     "shell.execute_reply": "2025-06-08T14:20:48.886791Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.867734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_network(X, y, conv, pool, full, lr=0.01, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            # Forward pass\n",
    "            conv_out = conv.forward(X[i])\n",
    "            pool_out = pool.forward(conv_out)\n",
    "            full_out = full.forward(pool_out)\n",
    "            loss = cross_entropy_loss(full_out.flatten(), y[i])\n",
    "            total_loss += loss\n",
    "\n",
    "            # Converting to One-Hot encoding\n",
    "            one_hot_pred = np.zeros_like(full_out)\n",
    "            one_hot_pred[np.argmax(full_out)] = 1\n",
    "            one_hot_pred = one_hot_pred.flatten()\n",
    "\n",
    "            num_pred = np.argmax(one_hot_pred)\n",
    "            num_y = np.argmax(y[i])\n",
    "\n",
    "            if num_pred == num_y:\n",
    "                correct_predictions += 1\n",
    "            # Backward pass\n",
    "            gradient = cross_entropy_loss_gradient(y[i], full_out.flatten()).reshape((-1, 1))\n",
    "            full_back = full.backward(gradient, lr)\n",
    "            pool_back = pool.backward(full_back, lr)\n",
    "            conv_back = conv.backward(pool_back, lr)\n",
    "\n",
    "        # Print epoch statistics\n",
    "        average_loss = total_loss / len(X)\n",
    "        accuracy = correct_predictions / len(X_train) * 100.0\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.888912Z",
     "iopub.status.busy": "2025-06-08T14:20:48.888596Z",
     "iopub.status.idle": "2025-06-08T14:20:48.911030Z",
     "shell.execute_reply": "2025-06-08T14:20:48.910121Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.888885Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(input_sample, conv, pool, full):\n",
    "    # Forward pass through Convolution and pooling\n",
    "    conv_out = conv.forward(input_sample)\n",
    "    pool_out = pool.forward(conv_out)\n",
    "    # Flattening\n",
    "    flattened_output = pool_out.flatten()\n",
    "    # Forward pass through fully connected layer\n",
    "    predictions = full.forward(flattened_output)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:48.912231Z",
     "iopub.status.busy": "2025-06-08T14:20:48.911946Z",
     "iopub.status.idle": "2025-06-08T14:20:49.366471Z",
     "shell.execute_reply": "2025-06-08T14:20:49.365465Z",
     "shell.execute_reply.started": "2025-06-08T14:20:48.912183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the Fashion MNIST dataset\n",
    "(train_images, train_labels), (_,_) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Run down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:49.367581Z",
     "iopub.status.busy": "2025-06-08T14:20:49.367347Z",
     "iopub.status.idle": "2025-06-08T14:20:49.397918Z",
     "shell.execute_reply": "2025-06-08T14:20:49.397036Z",
     "shell.execute_reply.started": "2025-06-08T14:20:49.367564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = train_images[:5000] / 255.0\n",
    "y_train = train_labels[:5000]\n",
    "\n",
    "X_test = train_images[5000:10000] / 255.0\n",
    "y_test = train_labels[5000:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:49.398965Z",
     "iopub.status.busy": "2025-06-08T14:20:49.398738Z",
     "iopub.status.idle": "2025-06-08T14:20:49.404541Z",
     "shell.execute_reply": "2025-06-08T14:20:49.403710Z",
     "shell.execute_reply.started": "2025-06-08T14:20:49.398949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Converting labels to One-Hot vectors for easy loss calculation, \n",
    "# and training stability\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:49.405779Z",
     "iopub.status.busy": "2025-06-08T14:20:49.405462Z",
     "iopub.status.idle": "2025-06-08T14:20:49.427334Z",
     "shell.execute_reply": "2025-06-08T14:20:49.426392Z",
     "shell.execute_reply.started": "2025-06-08T14:20:49.405754Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:49.430490Z",
     "iopub.status.busy": "2025-06-08T14:20:49.430190Z",
     "iopub.status.idle": "2025-06-08T14:20:49.443878Z",
     "shell.execute_reply": "2025-06-08T14:20:49.442863Z",
     "shell.execute_reply.started": "2025-06-08T14:20:49.430470Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "conv = Convolution(X_train[0].shape, 6, 1)\n",
    "pool = MaxPool(2)\n",
    "full = Fully_Connected(121, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:20:49.444978Z",
     "iopub.status.busy": "2025-06-08T14:20:49.444746Z",
     "iopub.status.idle": "2025-06-08T14:30:36.345795Z",
     "shell.execute_reply": "2025-06-08T14:30:36.344878Z",
     "shell.execute_reply.started": "2025-06-08T14:20:49.444960Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss: 1.0968 - Accuracy: 22.68%\n",
      "Epoch 2/50 - Loss: 0.9370 - Accuracy: 32.40%\n",
      "Epoch 3/50 - Loss: 0.8111 - Accuracy: 33.80%\n",
      "Epoch 4/50 - Loss: 0.7274 - Accuracy: 44.86%\n",
      "Epoch 5/50 - Loss: 0.6621 - Accuracy: 49.78%\n",
      "Epoch 6/50 - Loss: 0.6009 - Accuracy: 51.62%\n",
      "Epoch 7/50 - Loss: 0.5486 - Accuracy: 52.18%\n",
      "Epoch 8/50 - Loss: 0.4724 - Accuracy: 55.94%\n",
      "Epoch 9/50 - Loss: 0.3876 - Accuracy: 56.98%\n",
      "Epoch 10/50 - Loss: 0.3410 - Accuracy: 55.86%\n",
      "Epoch 11/50 - Loss: 0.2467 - Accuracy: 57.74%\n",
      "Epoch 12/50 - Loss: 0.1857 - Accuracy: 59.86%\n",
      "Epoch 13/50 - Loss: 0.1116 - Accuracy: 64.40%\n",
      "Epoch 14/50 - Loss: 0.0956 - Accuracy: 67.64%\n",
      "Epoch 15/50 - Loss: 0.0883 - Accuracy: 70.18%\n",
      "Epoch 16/50 - Loss: 0.0848 - Accuracy: 71.14%\n",
      "Epoch 17/50 - Loss: 0.0819 - Accuracy: 72.56%\n",
      "Epoch 18/50 - Loss: 0.0803 - Accuracy: 73.38%\n",
      "Epoch 19/50 - Loss: 0.0784 - Accuracy: 73.78%\n",
      "Epoch 20/50 - Loss: 0.0766 - Accuracy: 74.46%\n",
      "Epoch 21/50 - Loss: 0.0758 - Accuracy: 74.52%\n",
      "Epoch 22/50 - Loss: 0.0749 - Accuracy: 75.10%\n",
      "Epoch 23/50 - Loss: 0.0740 - Accuracy: 75.46%\n",
      "Epoch 24/50 - Loss: 0.0732 - Accuracy: 75.40%\n",
      "Epoch 25/50 - Loss: 0.0720 - Accuracy: 75.84%\n",
      "Epoch 26/50 - Loss: 0.0714 - Accuracy: 76.00%\n",
      "Epoch 27/50 - Loss: 0.0706 - Accuracy: 76.46%\n",
      "Epoch 28/50 - Loss: 0.0702 - Accuracy: 76.42%\n",
      "Epoch 29/50 - Loss: 0.0693 - Accuracy: 76.76%\n",
      "Epoch 30/50 - Loss: 0.0691 - Accuracy: 77.14%\n",
      "Epoch 31/50 - Loss: 0.0683 - Accuracy: 77.14%\n",
      "Epoch 32/50 - Loss: 0.0681 - Accuracy: 77.16%\n",
      "Epoch 33/50 - Loss: 0.0676 - Accuracy: 77.36%\n",
      "Epoch 34/50 - Loss: 0.0675 - Accuracy: 77.26%\n",
      "Epoch 35/50 - Loss: 0.0670 - Accuracy: 77.48%\n",
      "Epoch 36/50 - Loss: 0.0663 - Accuracy: 77.84%\n",
      "Epoch 37/50 - Loss: 0.0655 - Accuracy: 77.72%\n",
      "Epoch 38/50 - Loss: 0.0653 - Accuracy: 77.80%\n",
      "Epoch 39/50 - Loss: 0.0650 - Accuracy: 78.06%\n",
      "Epoch 40/50 - Loss: 0.0644 - Accuracy: 78.16%\n",
      "Epoch 41/50 - Loss: 0.0640 - Accuracy: 78.30%\n",
      "Epoch 42/50 - Loss: 0.0639 - Accuracy: 78.46%\n",
      "Epoch 43/50 - Loss: 0.0636 - Accuracy: 78.58%\n",
      "Epoch 44/50 - Loss: 0.0630 - Accuracy: 78.58%\n",
      "Epoch 45/50 - Loss: 0.0633 - Accuracy: 78.58%\n",
      "Epoch 46/50 - Loss: 0.0629 - Accuracy: 78.78%\n",
      "Epoch 47/50 - Loss: 0.0628 - Accuracy: 78.82%\n",
      "Epoch 48/50 - Loss: 0.0626 - Accuracy: 78.74%\n",
      "Epoch 49/50 - Loss: 0.0625 - Accuracy: 78.94%\n",
      "Epoch 50/50 - Loss: 0.0621 - Accuracy: 79.04%\n"
     ]
    }
   ],
   "source": [
    "train_network(X_train, y_train, conv, pool, full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:30:36.346807Z",
     "iopub.status.busy": "2025-06-08T14:30:36.346536Z",
     "iopub.status.idle": "2025-06-08T14:30:39.717149Z",
     "shell.execute_reply": "2025-06-08T14:30:39.716420Z",
     "shell.execute_reply.started": "2025-06-08T14:30:36.346779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for data in X_test:\n",
    "    pred = predict(data, conv, pool, full)\n",
    "    one_hot_pred = np.zeros_like(pred)\n",
    "    one_hot_pred[np.argmax(pred)] = 1\n",
    "    predictions.append(one_hot_pred.flatten())\n",
    "\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T14:30:39.718575Z",
     "iopub.status.busy": "2025-06-08T14:30:39.718321Z",
     "iopub.status.idle": "2025-06-08T14:30:39.730875Z",
     "shell.execute_reply": "2025-06-08T14:30:39.730055Z",
     "shell.execute_reply.started": "2025-06-08T14:30:39.718556Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7566"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions, y_test)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
